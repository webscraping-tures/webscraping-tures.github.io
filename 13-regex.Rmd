# Regular expressions {#regex}

``` {r, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(cache.path = 'cache/')
```


In web scraping, we are often dealing with text data that has been collected
from a website and may include information that is not easily accessible and
usable in data analysis. We are interested either in detecting the occurrence of
certain words or in extracting some information from the strings in our data.
For these purposes we will use some functions from the core tidyverse package
stringr. We will also use *regular expressions*, a powerful and flexible formal
representation of characters that we can use to select substrings by their
content.

This chapter will make use of some practical examples, introducing the basics of
regular expressions and stringr. This can only be a starting point; if you want
to follow the road of web scraping, you most probably will have to further your
knowledge on regular expressions at some point. I would recommended reading the
chapter on strings from "R for Data Science" by Wickham and Grolemund as a next
step: <https://r4ds.had.co.nz/strings.html>{target="_blank"}, as well as the
RStudio Cheat Sheet on stringr:
<https://raw.githubusercontent.com/rstudio/cheatsheets/master/strings.pdf>{target="_blank"}.


## Cleaning the `district` column

``` {r message = FALSE}
library(tidyverse)

load("reports.RData")
```

In our example the data on police reports contain the district a report refers
to as a column which needs some cleaning to be usable.

``` {r}
reports %>%
  select(District) %>%
  head(n = 10)
```

One problem we encounter here is that each string begins with "Ereignisort: ".
We want to get rid of this substring, as it does not contain any useful
information. With `str_remove()` we can remove substrings from a string. Like
all stringr functions we will use here, `str_remove()` takes the string(s) to be
applied to, as its first argument. The argument `pattern =` specifies a regular
expression for the pattern that is to be matched and removed. In the code block
below, all strings from `District` are passed through the pipe and
`"Ereignisort: ` is removed. We are using the most basic form of a regular
expression here which is the exact matching of characters. In general, the
complete regular expression is enclosed by `"`.


``` {r}
reports$District %>%
  str_remove(pattern = "Ereignisort: ") %>%
  head(n = 10)
```

We could keep the substring but translate it to English. For this, we use
`str_replace()` which also matches a regular expression, but replaces it with a
string specified in `replacement =`. Here, the pattern is shortened to
`"Ereignisort"`, as we want to keep the `": "`.

``` {r}
reports$District %>%
  str_replace(pattern = "Ereignisort", replacement = "District") %>%
  head(n = 10)
```

In the same way, we can replace the `": "` substring with a dash.

``` {r}
reports$District %>%
  str_replace(pattern = ": ", replacement = "-") %>%
  head(n = 10)
```

In chapter \@ref(dplyr) we saw district names with two parts that are sometimes
written with and sometimes without whitespace around the dash, as seen here:

``` {r}
reports %>%
  group_by(District) %>%
  summarize(reports = n())
```

We can easily unify those names using `str_replace` and regular expressions.

``` {r}
reports %>%
  mutate(District = str_replace(District, pattern = " - ", replacement = "-")) %>%
  group_by(District) %>%
  summarize(reports = n())
```

If we want to remove the whitespace and unify the names in the process, we use
`str_remove()` and the regular expression `"\\s"` being a shortcut for matching
all kinds of whitespace.

At this point we have to talk about *escape characters*. Some characters used in
regular expressions have a special meaning, e.g. `"."`, `"?"` or `"*"`. If we
just write one of those characters in a regular expression, R will not interpret
it as a literal character but by its special meaning. `"."` used in a regular
expression for example, stands for *any* character. If we want to match a
literal `.` in a string though, we have to escape the dot by using the escape
character `\` or actually two, telling R to take the next character
literally. So to match a dot, we write `"\\."`.

If this seems confusing and needlessly complicated, save your rage for when you
find out what you have to write to match *one* literal backslash in a string:
`\\\\`. Some commentary on this: <https://xkcd.com/1638/>{target="_blank"}

Escape characters are hard to understand when starting out using regular
expressions, but for now it is enough to know that some characters have to be
escaped and that you find a full list of those in the cheat sheet linked above.

In a similar way, we have to use two escape characters in `"\\s"` to make R
interpret it not as an "s" but as the shortcut for whitespace characters we want
to use:

``` {r}
reports %>%
  mutate(District = str_remove(District, pattern = "\\s")) %>%
  group_by(District) %>%
  summarize(reports = n())
```

This did not work as expected. The whitespace following the `":"` was removed,
but not the whitespace around the dashes. This is the case because most of the
stringr functions stop after they found the first match for the pattern in a
string. But there are versions of the functions that do not stop after their
first match, ending in `_all`: e.g. `str_replace_all()`. So if we use
`str_remove_all()` in our code, all occurrences of whitespace will be removed.

``` {r}
reports %>%
  mutate(District = str_remove_all(District, pattern = "\\s")) %>%
  group_by(District) %>%
  summarize(reports = n())
```

## Detecting robberies in police reports

When collecting the data on police reports, we also scraped the short
description of the report's contents, but we did no analysis on these in
chapters \@ref(dplyr) & \@ref(ggplot). We could try to categorize the texts into
types of crimes using regular expressions. Doing this properly, would require a
lot of planning. We would have to decide which categories of crimes we want to
extract and construct flexible regular expressions for each of these. Please
understand the following merely as a first outline for how to approach such a
project.

Let us focus solely on robberies. To begin with, we want to detect all strings
that contain the term "raub" in some form. `str_detect()` determines whether a
pattern was found in a string, returning `TRUE` or `FALSE`. We can then count
the number of strings for which the result is `TRUE`-- remember `TRUE` is equal
to $1$, `FALSE` equal to $0$ -- using `sum()`.

``` {r}
reports$Report %>%
  str_detect(pattern = "raub") %>%
  sum()
```

But what if a text begins with "Raub". In this case the "R" will be upper case.
Pattern matching is case sensitive and that means that "Raub" is not equal to
"raub". If we want both ways of writing the term to be counted as equal, we have
to write a regular expression that allows for either an upper or lower case "r"
as the first character. For this we can define a *class* which contains both
characters enclosed by `[]`. `"[Rr]aub"` means that we want to find *either* an
"R" or an "r" as the first character and "aub" after this; only one of the
characters from the class is matched.

``` {r}
reports$Report %>%
  str_detect(pattern = "[Rr]aub") %>%
  sum()
```

If we also want to detect terms like "Räuber" or "räuberische", we have to allow
for an "ä" instead of the "a" as the second character by defining a class for
the second position in the term:


``` {r}
reports$Report %>%
  str_detect(pattern = "[rR][aä]ub") %>%
  sum()
```


Let us have a look at some of the strings which returned a `TRUE` match, using
`str_detect()` in `filter()`: telling R we want to see only lines from `reports`
for which the pattern could be found, and only the first $10$ of those.

``` {r}
reports %>%
  filter(str_detect(Report, pattern = "[Rr][aä]ub")) %>% 
  select(Report) %>% 
  head(n=10)
```

This looks good at a first glance, but why was a report on a motorcycle accident
included? Because the word "Rettungshubschrauber" also has "raub" in it. You
see, how reliably detecting a simple string such as "raub" gets complicated very
quickly.

At this point, we would have to put in the hours and define a list of phrases
referring to robberies that we actually want to select while constructing
regular expressions that select those phrases and only those. This is beyond the
scope of this introductory example, but as a first approximation we could say
that we want to find all instances in which the words begin with a capital "R",
as in "*Raub*" or "*Räub*er", or where "aub" and "äub" are prefixed with
"ge", "be" or "zu", as in "*geraub*t", "*beraub*t", or "aus*zuraub*en". To
achieve this, the regular expression has to allow for four optional substrings,
using *grouping* and the "OR" operator `|`. Groups are defined by enclosing
several expressions in parentheses. While groups have advanced functionality,
for now you can interpret them like parentheses in mathematics. The enclosed
expression is evaluated first and as a whole. If one of the prefixes, connected
by `|`, is found in a string and is then followed up by either "a" or "ä" and
"ub" after this, the pattern is matched.

``` {r}
reports %>%
  filter(str_detect(Report, pattern = "(R|ger|ber|zur)[aä]ub")) %>% 
  select(Report) %>% 
  head(n=10)
```

There are other words in the German language that are used to describe the
concept of robberies. Adding all of them and the several individual pre- and/or
suffixes that have to be taken into account to reliably select the terms we want
to select and none of those we do not want to select, is beyond the scope of
this example. But we can at least add one further word to the regular
expression. Using the `|` operator we extend the regular expression to also
detect "dieb" with an upper or lower case "d". The expression now selects all
ways of writing "raub" and "dieb" we allowed for.

``` {r}
reports %>%
  filter(str_detect(Report, pattern = "(R|ger|ber|zur)[aä]ub|[Dd]ieb")) %>% 
  select(Report) %>% 
  head(n=10)
```

Now that we have constructed a provisional regular expression that can detect
reports that are related to robberies, we can compute their number and relative
proportion. Remember, we are dealing with a logical vector of ones and zeros:
`sum()` counts all ones and thus returns the absolute number of reports and
`mean()` divides the number of ones by the number of all reports, thus returning
the relative proportion.

``` {r}
reports$Report %>%
  str_detect(pattern = "(R|ger|ber|zur)[aä]ub|[Dd]ieb") %>%
  sum()

reports$Report %>%
  str_detect(pattern = "(R|ger|ber|zur)[aä]ub|[Dd]ieb") %>%
  mean()
```


## Extracting details from a list of names

The website
<https://www.bundeswahlleiter.de/bundestagswahlen/2017/gewaehlte/bund-99/>{target="_blank"}
lists all German members of parliament in tables, with the first column holding
the full names and academic degrees in one character string. A common
application of regular expressions in the context of web scraping is to extract
substrings of interest from such text.

We will first scrape the data. The members of parliament are divided into 26
subpages, one for each first letter of their last names, in the form "a.html",
"b.html" and so on. We construct links to all these pages using the base R
object `letters`, a character vector conveniently containing all 26 letters of
the alphabet in lower case. We then read the links and extract the table cells
containing the names into a character vector, which is then transformed into a
tibble.

``` {r}
library(rvest)

website <- "https://www.bundeswahlleiter.de/bundestagswahlen/2017/gewaehlte/bund-99/"
links <- str_c(website, letters, ".html")

pages <- links %>%
  map(~ {
    Sys.sleep(2)
    read_html(.x)
  })

names <- pages %>%
  map(html_nodes, css = "th[scope='row']") %>%
  map(html_text, trim = TRUE) %>%
  unlist()

names_tbl <- tibble(
  full_name = names
)
```

Our goal is to extract the academic degree from strings of full names. We first
need to understand the pattern of how degrees are listed in those strings. Let
us look at an example:

``` {r}
names_tbl[65:69, ]
```

If the members of parliament carry an academic degree, the string begins with
it and the abbreviated titles always end in a dot. Based on this, we can start
constructing a regular expression that will be used to detect and extract
academic degrees.

We know that if there is a degree, it is listed at the beginning of the string.
We can refer to the beginning and ending of a string by using an *anchor*.
Writing `^` in a regular expression refers to the beginning of a string, `$` to
the ending. Being a predefined class that includes all upper and lower case
letters of the alphabet, we will use `[:alpha:]` to refer to letters in general.
`"^[:alpha:]"` will select *one* upper or lower case letter that is the first
character in a string.

We do not want to select only one character but complete titles. For this we
need to use *quantifiers*. These are used to define how often elements of an
expression are allowed or required to be repeated. If we know the exact number
of repetitions, we can set this number contained in `{}` after an element.
`"^[:alpha:]{2}"` will select the first two letters in each string; always
exactly *two*. The actual titles vary in the number of letters they contain. To
allow for variation in the number of repetitions we use the quantifiers `?`, `*`
and `+`. `?` stands for zero or one, `*` for zero or multiple and `+` for one or
multiple repetitions, multiple meaning $n >=1$.

`"^[:alpha:]+"` will select the word a string begins with. `[:alpha:]` does not
contain any whitespace characters. Therefore, the regular expression will begin
selecting letters at the beginning of a string until it "hits" a whitespace 
character. For members of parliament without a degree, this would select their
last name. To make sure we only select titles, we can make use of the fact that
all titles in this data end with a ".". As the dot is a special character --
standing for *any* character -- we have to escape it by using two backslashes.

The regular expression `"^[:alpha:]+\\."` selects all words at the beginning of
a string that end with a dot. We use it in the function `str_extract()` which
will extract the substring that is specified by the regular expression if it
could be matched in the string. We use the function inside of `mutate()` to
assign the extracted degrees into a new column. To get an overview of the
result, we group the data by this new column and count the occurrences per
group.

``` {r}
names_tbl %>%
  mutate(academic = str_extract(full_name, pattern = "^[:alpha:]+\\.")) %>%
  group_by(academic) %>%
  summarise(n())
```

We successfully identified a high percentage of doctors, as well as some
professors. In some cases, there actually are multiple titles -- i.e. "Prof.
Dr.". We can extend the expression to allow for this as well.

If there are two or more components to a title, they are separated by
whitespace; which we can refer to using `\\s`. After the whitespace there will
be another word ending in a dot. Thus we can reuse the first part of the
expression, without the anchor: `"\\s[:alpha:]+\\."`. Some members of parliament
have one title, others have multiple. We have to allow both. A quantifier that
follows a part of an expression grouped by enclosure in parentheses will refer
to the complete group. The regular expression `"(\\s[:alpha:]+\\.)*"` allows for
no additional title or for multiple ones. Appending this to the regular
expression used in the code above allows us to select and extract one or more
titles.

``` {r}
names_tbl %>%
  mutate(academic = str_extract(full_name, pattern = "^[:alpha:]+\\.(\\s[:alpha:]+\\.)*")) %>%
  group_by(academic) %>%
  summarise(n())
```
