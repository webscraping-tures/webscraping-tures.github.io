[["index.html", "Web Scraping mit R Einführung Was ist Web Scraping? Was lernen wir, was nicht? Technische Voraussetzungen", " Web Scraping mit R Jakob Tures 2021-02-20 Einführung WIP! Was ist Web Scraping? Ziele Zugang zu Daten die wir auf klassischem Wege nicht bekommen könnten Zugang zu neuen Formen von Daten die nur im Web denkbar sind (bspw. Kundenreviews, Nutzerverhalten) Was ist möglich: Beispiele Kriesel 3C Methoden Identifikation für unsere Fragestellung relevanter Webinhalte Zugriff auf Webinhalte aus einer Programmiersprache heraus (R, Python, etc.) Extraktion der für unsere Fragestellung relevanten Teilinhalte der Seite Säuberung und Überführung in ein für die Datenanalyse geeignetes Format -&gt; Datenanalyse Ethik Grundregeln, später Sitzung dazu Was lernen wir, was nicht? Grundstruktur des Web HTML, XML Überblick zu anderen Bausteinen die wir in der Wildnis treffen, ohne zu tief hineinzugehen Einführung in R Basics in R Studio Tidyverse tidy data dplyr ggplot rvest evtl. stringr Scraping Scrapen ganzer Seiten mit rvest CSS Selectors und Developement Tools zur Identifikation des Pfades einzelner Inhalte Extraktion dieser Pfade mit rvest Evtl. gezieltes Auslesen von XML Inhalten Was nicht: Umgang mit dynamischen Websites, javascript, Datenbankzugriffen usw. (hier nur grober Überblick was es alles gibt und das es Wege gibt damit umzugehen -&gt; Fortgeschrittene) Umgang mit Strings &amp; regular expressions (Hinweis dass sie nicht darum herumkommen wenn sie den Weg weitergehen möchten, kurzer Überblick dazu wenn Zeit reicht) Scrapen mit anderen packages oder Sprachen als R + rvest (evtl. Hinweis auf weitere verbreitete Möglichkeiten) Technische Voraussetzungen R + R Studio Installation Tutorial? Packages: easy way: install.packages(“tidyverse”) ordentlicher Text Editor Windows: Notepad ++ Mac: ? Linux: Atom Browser Chrome/Chromium (wegen der Developer Tools?) "],["html.html", "1 HTML als Grundbaustein des Web 1.1 HTML Tags", " 1 HTML als Grundbaustein des Web Was passiert, wenn wir eine URL wie https://webscraping-tures.github.io in einem Browser aufrufen? Wir bekommen zunächst einmal eine visuelle Darstellung der aufgerufenen Seite in unserem Browserfenster. Aus der Sicht des Nutzers einer Website, ist dies auch alles was wir wissen müssen. Unser Ziel – die Seite aufzurufen – ist an diesem Punkt bereits erreicht. Aus der Sicht des Web Scrapers, müssen wir aber verstehen, was im Hintergrund passiert. Die Links https://webscraping-tures.github.io und https://webscraping-tures.github.io/index.html sind im Ergebnis äquivalent. Denn tatsächlich wird in beiden Fällen eine HTML Datei aufgerufen, in welcher der Inhalt der Website in Form eines spezifischen Codes hinterlegt ist. Dieser Code wird von Ihrem Browser interpetiert und in eine visuelle Darstellung überführt, dem was sie aktuell vor sich sehen. Überzeugen Sie sich selbst. Mit einem Rechtsklick im Bereich dieses Texts und einem weiteren Klick auf “Seitenquelltext anzeigen” öffnet sich der HTML Code welcher dieser Seite zu Grunde liegt. Es ist an diesem Punkt völlig legitim, von der Flut aus ungewohnten Zeichen und Begriffen zunächst überfordert zu sein. Wer hätte gedacht, dass eine relativ einfache Website wie diese im Hintergrund so kompliziert sein kann? Aber die gute Nachricht ist, dass wir als Web Scraper nicht jedes Wort und Zeichen in einer HTML Datei verstehen müssen. Unser Ziel ist es die Teile einer Website zu identifizieren die für unsere Fragestellung relevant sind und diese gezielt aus dem HTML Code zu extrahieren. Dies ist möglicherweise nur eine einzelne Zeile aus einer HTML Datei mit tausenden von Zeilen. Müssen wir alle diese tausend Zeilen völlig verstehen? Nein, aber wir müssen die Struktur einer HTML Datei erfassen können, um diese eine Zeile an der wir interessiert sind auch identifizieren zu können. Bis dies soweit ist, haben wir noch ein gutes Stück Weg vor uns, am Ende dieses ersten Abschnitts werden Sie aber bereits ein grundlegendes Verständnis der Struktur und der Bestandteile eines HTML Dokuments haben und der Quelltext wird Ihnen bereits deutlich weniger “beeindruckend” erscheinen. 1.1 HTML Tags Die “Sprache” in der HTML Dateien verfasst sind, ist die Hypertext Markup Language, kurz HTML. Die Grundbausteine dieser Sprache, die “Vokabeln”, sind die sogenannten Tags. Begriffe die unter anderem dazu dienen, das HTML Dokument zu strukturieren, den Text zu formatieren, Links und Bilder einzufügen oder Listen und Tabellen zu erzeugen. Der Browser kennt die Bedeutung dieser Begriffe, kann sie interpretieren und die Website entsprechend der in den HTML Tags codierten Anweisungen visuell darstellen. Wie jede Sprache in der IT-Welt, folgt auch HTML dabei einer bestimmten “Grammatik”, der sogenannten Syntax. Glücklicherweise, fällt diese im Falle von HTML sehr einfach aus. Die für uns zentralen Tags und Sytaxregeln, werden im Folgendne genauer betrachtet. Betrachten Sie folgendes Beispiel: &lt;b&gt;Hello World!&lt;/b&gt; &lt;b&gt; ist ein Tag. Das b steht hier für bold, also fettgedruckt im Deutschen Sprachraum. Tags folgen stets dem selben Muster. Sie werden mit einem &lt; begonnen, dann folgt der Name des Tags – b – und sie werden mit einem &gt; beendet. Wichtig ist dabei, dass ein so geöffneter Tag im Normalfall auch erneut geschlossen werden muss. Dazu wird der selbe Tag erneut auf die selbe Art geschrieben wie der öffnende Tag, allerdings mit einem forward slash direkt vor dem Namen des Tags. In diesem Beispiel also, &lt;/b&gt;. Alles was von öffnendem und schließendem Tag im HTML Dokument umfasst wird, wird entsprechend der Bedeutung des Tags vom Browser interpretiert. Mit diesem Wissen, könnten wir schon eine erste Idee entwickeln, was das obige Beispiel bewirkt. Der Tag &lt;b&gt; steht für fettgedruckt und öffnender und schließender Tag &lt;b&gt;...&lt;/b&gt; umfassen den Text Hello World!. Dieser wird entsprechend der Bedeutung des Tags interpretiert, also als fettgedruckt dargestellt: Hello World! 1.1.1 hello_world.html Betrachten wir nun ein erstes vollständiges HTML Dokument: &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Hello World!&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;b&gt;Hello World!&lt;/b&gt; &lt;/body&gt; &lt;/html&gt; Genau dieses Dokument können Sie unter https://webscraping-tures.github.io/hello_world.html selbst im Browser betrachten. Lassen Sie uns die einzelnen Bestandteile betrachten: Die erste Zeile, die document type declaration, &lt;!DOCTYPE html&gt; unterrichtet den Browser darüber, welche HTML Version in dem Dokument eingesetzt wurde. &lt;!DOCTYPE HTML&gt; steht dabei für den aktuellen Standard HTML5. Wurde eine ältere HTML Version verwendet, kann dies an dieser Stelle deklariert werden um eine korrekte visuelle Repräsentation – trotz möglicher Veränderungen oder dem Wegfall bestimmter Funktionen im aktuellen Standard – sicherzustellen. Aus Sicht des Web Scrapers spielt die HTML Version aber im Normalfall keine Rolle. Interessanterweise bildet der &lt;!DOCTYPE html&gt; Tag eine der wenigen Ausnahmen von der Regel, dass ein einmal geöffneter Tag auch wieder geschlossen werden muss. Dies ist hier nicht nötig. Der eigentliche Inhalt des HTML Dokuments beginnt in Zeile 3 mit dem &lt;html&gt; Tag. Dieser wird erst in der letzten Zeile wieder geschlossen und umfasst somit den gesamten Inhalt des Dokuments. Der Tag teilt dabei dem Browser mit, dass alles was durch ihn umschlossen wird, HTML ist. Als nächstes folgt der Tag &lt;head&gt;. Alles was durch ihn umfasst wird, ist noch nicht Teil des Inhalts den wir im Browserfenster sehen. Hier werden in der Praxis vor allem Meta-Informationen hinterlegt – mehr dazu unter 1.1.5 – sowie erweiterte Funktionalitäten (JavaScript) und Designentscheidungen (Cascading Style Sheets – CSS) definiert oder aus externen Quellen eingebunden. Die beiden letzten Punkte sollen uns in dieser Einführung in das Web Scraping vorerst nicht weiter ablenken, wir sollten aber Wissen, dass Verweise auf .js und .css Dateien im &lt;head&gt; Tag auftauchen können und wir diese zunächst einmal selbstbewusst ignorieren können. In unserem Beispiel umfasst der &lt;head&gt; Tag auschschließlich einen weiteren Tag namens &lt;title&gt;, welcher wiederum den Text Hello World! einschließt. Der &lt;title&gt; Tag bestimmt, was wir in der Titelleise unseres Browser sehen, hier Hello World!. Alles was der &lt;body&gt; Tag umfasst, beschreibt endlich den Inhalt, den wir im Browserfenster sehen können. In diesem einfachen Beispiel ist nur eine Zeile enthalten. Der bereits bekannte &lt;b&gt;Tag umfasst den Text Hello World! womit uns dieser fettgedruckt im Browserfenster dargestellt wird. Damit kennen Sie nun bereits die Grundstruktur jeder HTML Datei. Noch eine Anmerkung zur technischen Seite: HTML Dokumente lassen sich grundsätzlich in jedem beliebigen Editor per Hand schreiben und müssen mit der Endung .html abgespeichert werden. Sie können dies testen indem Sie selbst einen beliebigen Texteditor starten, den obigen HTML Code kopieren, die Datei mit der Endung .html abspeichern und in einem Browser ihrer Wahl öffnen. Allerdings werden Websites heute in Normalfall nicht mehr per hand geschrieben da dies bei komplexeren Seiten nicht nur schwierig sondern auch sehr zeitintensiv würde. Eine vielzahl professioneller Tools und Unternehmen bieten inzwischen sehr viel effizientere Wege um Websites zu gestalten. So habe Ich die Seite die Sie gerade betrachten direkt in R Studio mit Hilfe des package “bookdown” verfasst, welches mir den Großteil der Layoutentscheidungen abnehmen konnte, so dass der Fokus meiner Arbeit auf den Inhalt der Seite gerichtet werden konnte. 1.1.2 Wichtige Tags weitere wichtige tags Formatierung (inkl. &lt;br&gt;) Struktur (&lt;p&gt;, &lt;h1&gt; usw) Listen Tabellen 1.1.3 Attribute generell Bsp. &lt;a href=\"\"&gt; =/= &lt;link&gt; 1.1.4 Spezielle Zeichen va. quotation, amersand,   wir erkennen sie generell an &amp;..; 1.1.5 &lt;head&gt; was daran ist relevant für scraping? "],["R1.html", "2 R &amp; R Studio", " 2 R &amp; R Studio "],["tidyverse.html", "3 Tidyverse 3.1 Philosophie 3.2 Tidy data 3.3 Pipe", " 3 Tidyverse 3.1 Philosophie 3.2 Tidy data 3.3 Pipe "],["rvest1.html", "4 Erstes Scraping mit rvest", " 4 Erstes Scraping mit rvest "],["css.html", "5 CSS selectors &amp; Developer Tools 5.1 CSS selectors 5.2 Developer Tools", " 5 CSS selectors &amp; Developer Tools 5.1 CSS selectors 5.2 Developer Tools "],["rvest2.html", "6 Fortgeschrittenes Scraping mit rvest", " 6 Fortgeschrittenes Scraping mit rvest "],["R2.html", "7 Transformation und Visualisierung im Tidyverse 7.1 Transformation mit dplyr 7.2 Visualisierung mit ggplot", " 7 Transformation und Visualisierung im Tidyverse 7.1 Transformation mit dplyr 7.2 Visualisierung mit ggplot "],["projekt1.html", "8 Beispielprojekt HTML Scraping", " 8 Beispielprojekt HTML Scraping "],["projekt2.html", "9 Beispielprojekt XML Scraping", " 9 Beispielprojekt XML Scraping "],["ethik.html", "10 Ethik &amp; good practice", " 10 Ethik &amp; good practice "],["web.html", "11 Weitere Formate im WWW 11.1 XML 11.2 JSON 11.3 AJAX 11.4 SQL 11.5 APIs", " 11 Weitere Formate im WWW 11.1 XML 11.2 JSON 11.3 AJAX 11.4 SQL 11.5 APIs "],["regex.html", "12 Regular Expressions", " 12 Regular Expressions "]]
