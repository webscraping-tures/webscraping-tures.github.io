<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9 Good practice | Web Scraping using R</title>
  <meta name="description" content="9 Good practice | Web Scraping using R" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="9 Good practice | Web Scraping using R" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="webscraping-tures/webscraping-tures.github.io" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9 Good practice | Web Scraping using R" />
  
  
  

<meta name="author" content="Jakob Tures" />


<meta name="date" content="2021-06-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="files.html"/>
<link rel="next" href="dplyr.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="libs/echarts4r-4.8.0/echarts-en.min.js"></script>
<script src="libs/echarts4r-4.8.0/ecStat.min.js"></script>
<script src="libs/echarts4r-4.8.0/dataTool.min.js"></script>
<script src="libs/echarts4r-binding-0.4.0/echarts4r.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
Web Scraping using R

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#what-is-web-scraping"><i class="fa fa-check"></i>What is web scraping?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-contents"><i class="fa fa-check"></i>Course contents</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#technical-requirements"><i class="fa fa-check"></i>Technical requirements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#conventions"><i class="fa fa-check"></i>Conventions</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#colophon"><i class="fa fa-check"></i>Colophon</a></li>
</ul></li>
<li class="part"><span><b>I Basics</b></span></li>
<li class="chapter" data-level="1" data-path="html.html"><a href="html.html"><i class="fa fa-check"></i><b>1</b> HTML as a cornerstone of the internet</a>
<ul>
<li class="chapter" data-level="1.1" data-path="html.html"><a href="html.html#html-tags"><i class="fa fa-check"></i><b>1.1</b> HTML-Tags</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="html.html"><a href="html.html#hello_world.html"><i class="fa fa-check"></i><b>1.1.1</b> hello_world.html</a></li>
<li class="chapter" data-level="1.1.2" data-path="html.html"><a href="html.html#important-tags"><i class="fa fa-check"></i><b>1.1.2</b> Important tags</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="html.html"><a href="html.html#attribute"><i class="fa fa-check"></i><b>1.2</b> Attributes</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="html.html"><a href="html.html#links"><i class="fa fa-check"></i><b>1.2.1</b> Links</a></li>
<li class="chapter" data-level="1.2.2" data-path="html.html"><a href="html.html#images"><i class="fa fa-check"></i><b>1.2.2</b> Images</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="html.html"><a href="html.html#entities"><i class="fa fa-check"></i><b>1.3</b> Entities</a></li>
</ul></li>
<li class="part"><span><b>II R Basics &amp; Tidyverse</b></span></li>
<li class="chapter" data-level="2" data-path="R1.html"><a href="R1.html"><i class="fa fa-check"></i><b>2</b> R &amp; R Studio</a>
<ul>
<li class="chapter" data-level="2.1" data-path="R1.html"><a href="R1.html#installing-r"><i class="fa fa-check"></i><b>2.1</b> Installing R</a></li>
<li class="chapter" data-level="2.2" data-path="R1.html"><a href="R1.html#rstudio"><i class="fa fa-check"></i><b>2.2</b> RStudio</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="R1.html"><a href="R1.html#overview"><i class="fa fa-check"></i><b>2.2.1</b> Overview</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="R1.html"><a href="R1.html#hello-world"><i class="fa fa-check"></i><b>2.3</b> Hello World!</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="R1.html"><a href="R1.html#calculating-with-r"><i class="fa fa-check"></i><b>2.3.1</b> Calculating with R</a></li>
<li class="chapter" data-level="2.3.2" data-path="R1.html"><a href="R1.html#comparison-operators"><i class="fa fa-check"></i><b>2.3.2</b> Comparison operators</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="R1.html"><a href="R1.html#objects"><i class="fa fa-check"></i><b>2.4</b> Objects</a></li>
<li class="chapter" data-level="2.5" data-path="R1.html"><a href="R1.html#vectors"><i class="fa fa-check"></i><b>2.5</b> Vectors</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="R1.html"><a href="R1.html#subsetting"><i class="fa fa-check"></i><b>2.5.1</b> Subsetting</a></li>
<li class="chapter" data-level="2.5.2" data-path="R1.html"><a href="R1.html#types-of-vectors"><i class="fa fa-check"></i><b>2.5.2</b> Types of vectors</a></li>
<li class="chapter" data-level="2.5.3" data-path="R1.html"><a href="R1.html#a-brief-look-at-lists"><i class="fa fa-check"></i><b>2.5.3</b> A brief look at lists</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="R1.html"><a href="R1.html#functions"><i class="fa fa-check"></i><b>2.6</b> Functions</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="R1.html"><a href="R1.html#help"><i class="fa fa-check"></i><b>2.6.1</b> Help</a></li>
<li class="chapter" data-level="2.6.2" data-path="R1.html"><a href="R1.html#examples-basic-statistical-functions"><i class="fa fa-check"></i><b>2.6.2</b> Examples: Basic statistical functions</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="R1.html"><a href="R1.html#ifelse-statements"><i class="fa fa-check"></i><b>2.7</b> If/Else statements</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="R2.html"><a href="R2.html"><i class="fa fa-check"></i><b>3</b> RStudio in practice &amp; the tidyverse</a>
<ul>
<li class="chapter" data-level="3.1" data-path="R2.html"><a href="R2.html#rstudio-workflow"><i class="fa fa-check"></i><b>3.1</b> RStudio Workflow</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="R2.html"><a href="R2.html#r-scripts"><i class="fa fa-check"></i><b>3.1.1</b> R Scripts</a></li>
<li class="chapter" data-level="3.1.2" data-path="R2.html"><a href="R2.html#projects"><i class="fa fa-check"></i><b>3.1.2</b> Projects</a></li>
<li class="chapter" data-level="3.1.3" data-path="R2.html"><a href="R2.html#comments"><i class="fa fa-check"></i><b>3.1.3</b> Comments</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="R2.html"><a href="R2.html#r-packages"><i class="fa fa-check"></i><b>3.2</b> R packages</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="R2.html"><a href="R2.html#installing-and-loading-packages"><i class="fa fa-check"></i><b>3.2.1</b> Installing and loading packages</a></li>
<li class="chapter" data-level="3.2.2" data-path="R2.html"><a href="R2.html#namespaces"><i class="fa fa-check"></i><b>3.2.2</b> Namespaces</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="R2.html"><a href="R2.html#tidyverse"><i class="fa fa-check"></i><b>3.3</b> Tidyverse</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="R2.html"><a href="R2.html#tibbles"><i class="fa fa-check"></i><b>3.3.1</b> Tibbles</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="R2.html"><a href="R2.html#additional-resources"><i class="fa fa-check"></i><b>3.4</b> Additional resources</a></li>
</ul></li>
<li class="part"><span><b>III Scraping</b></span></li>
<li class="chapter" data-level="4" data-path="rvest1.html"><a href="rvest1.html"><i class="fa fa-check"></i><b>4</b> First scraping with rvest</a>
<ul>
<li class="chapter" data-level="4.1" data-path="rvest1.html"><a href="rvest1.html#the-rvest-package"><i class="fa fa-check"></i><b>4.1</b> The rvest package</a></li>
<li class="chapter" data-level="4.2" data-path="rvest1.html"><a href="rvest1.html#hello_world.html-1"><i class="fa fa-check"></i><b>4.2</b> hello_world.html</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="rvest1.html"><a href="rvest1.html#read_html"><i class="fa fa-check"></i><b>4.2.1</b> read_html()</a></li>
<li class="chapter" data-level="4.2.2" data-path="rvest1.html"><a href="rvest1.html#html_nodes"><i class="fa fa-check"></i><b>4.2.2</b> html_nodes()</a></li>
<li class="chapter" data-level="4.2.3" data-path="rvest1.html"><a href="rvest1.html#html_text"><i class="fa fa-check"></i><b>4.2.3</b> html_text()</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="rvest1.html"><a href="rvest1.html#countries-of-the-world"><i class="fa fa-check"></i><b>4.3</b> Countries of the World</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="rvest1.html"><a href="rvest1.html#country-names"><i class="fa fa-check"></i><b>4.3.1</b> Country names</a></li>
<li class="chapter" data-level="4.3.2" data-path="rvest1.html"><a href="rvest1.html#capitals-population-and-area"><i class="fa fa-check"></i><b>4.3.2</b> Capitals, population and area</a></li>
<li class="chapter" data-level="4.3.3" data-path="rvest1.html"><a href="rvest1.html#merge-into-one-tibble"><i class="fa fa-check"></i><b>4.3.3</b> Merge into one tibble</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="css-selectors-developer-tools.html"><a href="css-selectors-developer-tools.html"><i class="fa fa-check"></i><b>5</b> CSS selectors &amp; Developer Tools</a>
<ul>
<li class="chapter" data-level="5.1" data-path="css-selectors-developer-tools.html"><a href="css-selectors-developer-tools.html#css"><i class="fa fa-check"></i><b>5.1</b> CSS selectors</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="css-selectors-developer-tools.html"><a href="css-selectors-developer-tools.html#classes"><i class="fa fa-check"></i><b>5.1.1</b> Classes</a></li>
<li class="chapter" data-level="5.1.2" data-path="css-selectors-developer-tools.html"><a href="css-selectors-developer-tools.html#ids"><i class="fa fa-check"></i><b>5.1.2</b> IDs</a></li>
<li class="chapter" data-level="5.1.3" data-path="css-selectors-developer-tools.html"><a href="css-selectors-developer-tools.html#attributes"><i class="fa fa-check"></i><b>5.1.3</b> Attributes</a></li>
<li class="chapter" data-level="5.1.4" data-path="css-selectors-developer-tools.html"><a href="css-selectors-developer-tools.html#hierarchy-levels"><i class="fa fa-check"></i><b>5.1.4</b> Hierarchy levels</a></li>
<li class="chapter" data-level="5.1.5" data-path="css-selectors-developer-tools.html"><a href="css-selectors-developer-tools.html#further-selectors"><i class="fa fa-check"></i><b>5.1.5</b> Further selectors</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="css-selectors-developer-tools.html"><a href="css-selectors-developer-tools.html#developer-tools"><i class="fa fa-check"></i><b>5.2</b> Developer Tools</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="rvest2.html"><a href="rvest2.html"><i class="fa fa-check"></i><b>6</b> Scraping of tables &amp; dynamic websites</a>
<ul>
<li class="chapter" data-level="6.1" data-path="rvest2.html"><a href="rvest2.html#scraping-of-tables"><i class="fa fa-check"></i><b>6.1</b> Scraping of tables</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="rvest2.html"><a href="rvest2.html#table-with-css-selectors-from-wikipedia"><i class="fa fa-check"></i><b>6.1.1</b> Table with CSS selectors from Wikipedia</a></li>
<li class="chapter" data-level="6.1.2" data-path="rvest2.html"><a href="rvest2.html#scraping-multiple-tables"><i class="fa fa-check"></i><b>6.1.2</b> Scraping multiple tables</a></li>
<li class="chapter" data-level="6.1.3" data-path="rvest2.html"><a href="rvest2.html#tabellen-mit-nas"><i class="fa fa-check"></i><b>6.1.3</b> Tabellen mit NAs</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="rvest2.html"><a href="rvest2.html#dynamische-websites"><i class="fa fa-check"></i><b>6.2</b> Dynamische Websites</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="rvest2.html"><a href="rvest2.html#html-forms-and-html-queries"><i class="fa fa-check"></i><b>6.2.1</b> HTML forms and HTML queries</a></li>
<li class="chapter" data-level="6.2.2" data-path="rvest2.html"><a href="rvest2.html#html-forms"><i class="fa fa-check"></i><b>6.2.2</b> HTML forms</a></li>
<li class="chapter" data-level="6.2.3" data-path="rvest2.html"><a href="rvest2.html#the-query"><i class="fa fa-check"></i><b>6.2.3</b> The query</a></li>
<li class="chapter" data-level="6.2.4" data-path="rvest2.html"><a href="rvest2.html#manipulating-the-query-and-scraping-the-result"><i class="fa fa-check"></i><b>6.2.4</b> Manipulating the query and scraping the result</a></li>
<li class="chapter" data-level="6.2.5" data-path="rvest2.html"><a href="rvest2.html#additional-resources-1"><i class="fa fa-check"></i><b>6.2.5</b> Additional resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="rvest3.html"><a href="rvest3.html"><i class="fa fa-check"></i><b>7</b> Scraping of multi-page websites</a>
<ul>
<li class="chapter" data-level="7.1" data-path="rvest3.html"><a href="rvest3.html#index-pages"><i class="fa fa-check"></i><b>7.1</b> Index-pages</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="rvest3.html"><a href="rvest3.html#scraping-of-the-index"><i class="fa fa-check"></i><b>7.1.1</b> Scraping of the index</a></li>
<li class="chapter" data-level="7.1.2" data-path="rvest3.html"><a href="rvest3.html#iteration-with-map"><i class="fa fa-check"></i><b>7.1.2</b> Iteration with map()</a></li>
<li class="chapter" data-level="7.1.3" data-path="rvest3.html"><a href="rvest3.html#scraping-the-sub-pages"><i class="fa fa-check"></i><b>7.1.3</b> Scraping the sub-pages</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="rvest3.html"><a href="rvest3.html#pagination"><i class="fa fa-check"></i><b>7.2</b> Pagination</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="rvest3.html"><a href="rvest3.html#the-query-1"><i class="fa fa-check"></i><b>7.2.1</b> The query</a></li>
<li class="chapter" data-level="7.2.2" data-path="rvest3.html"><a href="rvest3.html#sub-pgs"><i class="fa fa-check"></i><b>7.2.2</b> Scraping the sub-pages</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="files.html"><a href="files.html"><i class="fa fa-check"></i><b>8</b> Downloading and saving files</a>
<ul>
<li class="chapter" data-level="8.1" data-path="files.html"><a href="files.html#csv-files"><i class="fa fa-check"></i><b>8.1</b> CSV files</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="files.html"><a href="files.html#parsing-a-csv-file"><i class="fa fa-check"></i><b>8.1.1</b> Parsing a CSV file</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="files.html"><a href="files.html#downloading-files"><i class="fa fa-check"></i><b>8.2</b> Downloading files</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="files.html"><a href="files.html#parsing-the-csv-files"><i class="fa fa-check"></i><b>8.2.1</b> Parsing the csv files</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="files.html"><a href="files.html#saving-data-files"><i class="fa fa-check"></i><b>8.3</b> Saving data files</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="good-practice.html"><a href="good-practice.html"><i class="fa fa-check"></i><b>9</b> Good practice</a>
<ul>
<li class="chapter" data-level="9.1" data-path="good-practice.html"><a href="good-practice.html#we-are-no-web-crawlers"><i class="fa fa-check"></i><b>9.1</b> We are no web crawlers</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="good-practice.html"><a href="good-practice.html#on-robots.txt-files"><i class="fa fa-check"></i><b>9.1.1</b> On robots.txt files</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="good-practice.html"><a href="good-practice.html#reduce-traffic"><i class="fa fa-check"></i><b>9.2</b> Reduce traffic</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="good-practice.html"><a href="good-practice.html#waiting-times-in-action"><i class="fa fa-check"></i><b>9.2.1</b> Waiting times in action</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="good-practice.html"><a href="good-practice.html#citation-and-additional-resource"><i class="fa fa-check"></i><b>9.3</b> Citation and additional resource</a></li>
</ul></li>
<li class="part"><span><b>IV Data analysis</b></span></li>
<li class="chapter" data-level="10" data-path="dplyr.html"><a href="dplyr.html"><i class="fa fa-check"></i><b>10</b> Transformation with dplyr</a>
<ul>
<li class="chapter" data-level="10.1" data-path="dplyr.html"><a href="dplyr.html#filter"><i class="fa fa-check"></i><b>10.1</b> <code>filter()</code></a></li>
<li class="chapter" data-level="10.2" data-path="dplyr.html"><a href="dplyr.html#select"><i class="fa fa-check"></i><b>10.2</b> <code>select()</code></a></li>
<li class="chapter" data-level="10.3" data-path="dplyr.html"><a href="dplyr.html#rename"><i class="fa fa-check"></i><b>10.3</b> <code>rename()</code></a></li>
<li class="chapter" data-level="10.4" data-path="dplyr.html"><a href="dplyr.html#mutate"><i class="fa fa-check"></i><b>10.4</b> <code>mutate()</code></a></li>
<li class="chapter" data-level="10.5" data-path="dplyr.html"><a href="dplyr.html#summarise-group_by"><i class="fa fa-check"></i><b>10.5</b> <code>summarise()</code> &amp; <code>group_by()</code></a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ggplot.html"><a href="ggplot.html"><i class="fa fa-check"></i><b>11</b> Graphical analysis with ggplot</a>
<ul>
<li class="chapter" data-level="11.1" data-path="ggplot.html"><a href="ggplot.html#ggplot-syntax"><i class="fa fa-check"></i><b>11.1</b> ggplot syntax</a></li>
<li class="chapter" data-level="11.2" data-path="ggplot.html"><a href="ggplot.html#aesthtetics"><i class="fa fa-check"></i><b>11.2</b> Aesthtetics</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="ggplot.html"><a href="ggplot.html#continuous"><i class="fa fa-check"></i><b>11.2.1</b> Continuous</a></li>
<li class="chapter" data-level="11.2.2" data-path="ggplot.html"><a href="ggplot.html#continuous-x-continuous"><i class="fa fa-check"></i><b>11.2.2</b> Continuous x Continuous</a></li>
<li class="chapter" data-level="11.2.3" data-path="ggplot.html"><a href="ggplot.html#discrete-x-continuous"><i class="fa fa-check"></i><b>11.2.3</b> Discrete x Continuous</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="ggplot.html"><a href="ggplot.html#tuning-the-output"><i class="fa fa-check"></i><b>11.3</b> Tuning the output</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="regex.html"><a href="regex.html"><i class="fa fa-check"></i><b>12</b> Regular expressions</a>
<ul>
<li class="chapter" data-level="12.1" data-path="regex.html"><a href="regex.html#str_detect"><i class="fa fa-check"></i><b>12.1</b> str_detect()</a></li>
<li class="chapter" data-level="12.2" data-path="regex.html"><a href="regex.html#basic-pattern-matching"><i class="fa fa-check"></i><b>12.2</b> Basic pattern matching</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="regex.html"><a href="regex.html#literal-characters"><i class="fa fa-check"></i><b>12.2.1</b> Literal characters</a></li>
<li class="chapter" data-level="12.2.2" data-path="regex.html"><a href="regex.html#escaping-metacharacters"><i class="fa fa-check"></i><b>12.2.2</b> Escaping metacharacters</a></li>
<li class="chapter" data-level="12.2.3" data-path="regex.html"><a href="regex.html#character-classes"><i class="fa fa-check"></i><b>12.2.3</b> Character classes</a></li>
<li class="chapter" data-level="12.2.4" data-path="regex.html"><a href="regex.html#anchors"><i class="fa fa-check"></i><b>12.2.4</b> Anchors</a></li>
<li class="chapter" data-level="12.2.5" data-path="regex.html"><a href="regex.html#quantifiers"><i class="fa fa-check"></i><b>12.2.5</b> Quantifiers</a></li>
<li class="chapter" data-level="12.2.6" data-path="regex.html"><a href="regex.html#groups"><i class="fa fa-check"></i><b>12.2.6</b> Groups</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="regex.html"><a href="regex.html#practical-application"><i class="fa fa-check"></i><b>12.3</b> Practical application</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="regex.html"><a href="regex.html#str_count"><i class="fa fa-check"></i><b>12.3.1</b> str_count()</a></li>
<li class="chapter" data-level="12.3.2" data-path="regex.html"><a href="regex.html#str_extract-str_match"><i class="fa fa-check"></i><b>12.3.2</b> str_extract() &amp; str_match()</a></li>
<li class="chapter" data-level="12.3.3" data-path="regex.html"><a href="regex.html#str_replace"><i class="fa fa-check"></i><b>12.3.3</b> str_replace()</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Web Scraping using R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="good_practice" class="section level1" number="9">
<h1><span class="header-section-number">9</span> Good practice</h1>
<p>This chapter concerns itself with questions regarding good practice of web
scraping and how to scrape responsibly. There is no wrong or right answer to
these questions. But in my view, it is a privilege that we are able to access
this wealth of data and we should treat it this way. Why? We have a
responsibility towards the people, institutions and companies whose data we
collect to respect certain boundaries and guidelines of data collection. These
boundaries might have been set by others or might be constraints we impose upon
ourselves.</p>
<p>I will not talk about the legal situation concerning web scraping. Firstly, I am
not an expert on the legalities and do not feel equipped to give any responsible
advice. Secondly, this is a relatively new field and legal rules might change.
Thirdly, the specific rules you have to adhere to may very well depend on the
context of your scraping project. Maybe it is allowed to collect certain data
for use in a scientific project but not for use in a commercial one. Maybe
certain types of data are not allowed to be collected at all. When in doubt, try
to get advice from your superiors or experts on the legal questions surrounding
web scraping and privacy laws.</p>
<p>Nonetheless, if we follow some basic principles of good practice, we can design
our web scraping projects in a way that is respectful to the owners of the data
and to our own standards of responsible data collection. So to boil it down:</p>
<ul>
<li><p>Rule #1 of the scrape club: Scrape responsibly and with respect to the data
sources.</p></li>
<li><p>Rule #2 of the scrape club: Scrape responsibly and with respect to the data
sources!</p></li>
</ul>
<div id="we-are-no-web-crawlers" class="section level2" number="9.1">
<h2><span class="header-section-number">9.1</span> We are no web crawlers</h2>
<p>Web crawlers – also known as web spiders or robots – are pieces of software
that aim at collecting and indexing all content on the internet. Web crawlers
are, for example, operated by search engines whose aim is to index the content of
the web and make it accessible via their search interface.</p>
<p>We are not web crawlers. It is not our aim to indiscriminately and
systematically collect every piece of data on the web. Web scraping is aimed at
extracting some specific data as precisely as possible and analysing the
collected data in a specific usage context, in our case scientific research.</p>
<p>What does this imply for a good practice of web scraping?</p>
<p><strong>Collect only what we need</strong></p>
<p>This means that we have to think hard about which pieces of data we actually
have to collect to meet our aims, <em>before</em> we start collecting. We seldom need
every subpage of a website, so we should only download those that contain data
of interest.</p>
<p><strong>Use an API if there is one</strong></p>
<p>Some websites may give us access to an API, an
<em>application programming interface</em>. APIs in the web context are mostly used for
allowing third party sites and applications to access the services a website
provides. For example, YouTube’s IFrame player API is used when a YouTube Video
is embedded in a third party site. The API gives accesss to the video and much
of YouTube’s functionality. Another example would be Twitter’s API that can be
used by tweet reader apps to access your tweets.</p>
<p>In many cases, we can use these APIs to directly access the data we are
interested in instead of scraping the raw HTML code for it. Sometimes the APIs
are openly accessible, sometimes we have to apply for access first. For example,
if we want to use Twitter’s API to collect tweets for scientific analysis, we
have to fill out a form, describing our project and the planned data usage, and
then await approval. This extra work might gain us a more direct access to
cleaner data. Additionally, if we use an API we automatically play by the rules
of the provider.</p>
<p>So, if there is an API we can access and it also gives us access to the data we
are interested in, it might be a good idea to use the API instead of
“traditional” scraping techniques. The technical details of accessing APIs are
beyond the scope of this introduction. Also APIs can differ tremendously in
their functionality. The first step should always be to read the APIs
documentation. You can also check whether there already is an R package that
simplifies access to an API, e.g. TwitteR or Rfacebook, before you start writing
your own scripts to access an API.</p>
<p><strong>Anonymisation of personal data</strong></p>
<p>Whenever we are collecting personal data that could be used to identify these
persons, we should anonymise any information that could lead to identification.
This primarily concerns real names in customer reviews, forums and so on. I
would argue that this should also extend to user names in general. Most of the
time, we do not need the actual names and any simple numeric identifier
constructed by us would suffice to discern users during the analysis. If we
cannot directly anonymise the data during collection, we should do this after
collection. Especially if results of the analysis or a constructed data set are
to be publicly released, anonymisation is paramount.</p>
<p><strong>robots.txt</strong></p>
<p>Many websites have set up a file called robots.txt on their servers which is
predominantly aimed at informing automatic web crawlers on which parts of the
website they are allowed to collect. While the robots.txt files may ask the
crawlers to stay out of certain subfolders of a website, they have no power in
actually stopping them. If the crawler is polite, it will follow the guidelines
of the robots.txt.</p>
<p>It may be up to debate whether web scrapers should follow the robots.txt
guidelines, as we have already established that we are no web crawlers. In my
opinion we should at least take a look at these files when planning a
project. If the data we plan to collect is excluded in the guidelines, we have
to decide if we still want to go forward. Is the collection of this specific
piece of data really necessary? Do I have support by superiors or my employer?
We can also always contact the website operator, describe our project and kindly
ask for permission.</p>
<div id="on-robots.txt-files" class="section level3" number="9.1.1">
<h3><span class="header-section-number">9.1.1</span> On robots.txt files</h3>
<p>The robots.txt files are usually accessible by appending the URL of the mainpage
of a website. If you do not find a robots.txt in this way for a website you are
interested in, there most probably is none. For example to access the robots.txt
file for the website <a href="https://www.wahlrecht.de/" target="_blank">https://www.wahlrecht.de/</a> we can use the
URL <a href="https://www.wahlrecht.de/robots.txt" class="uri">https://www.wahlrecht.de/robots.txt</a>{target_blank}.</p>
<p>Let us briefly look at the structure of this file. Its first block looks like
this:</p>
<pre><code>User-agent: *
Disallow: /cgi-bin/
Disallow: /temp/
Disallow: /ueberhang/wpb/
Disallow: /ueberhang/chronic/</code></pre>
<p>The field “User-agent” defines to which crawlers the rules apply to. "*" is
short for everyone. The “Disallow” fields define which subdirectories of the
website may not be accessed by the particular User-agent. So in this case, no
User-agent may access the subdirectories “/cgi-bin/”, “/temp/”, and so on.</p>
<p>Let’s continue to the second block:</p>
<pre><code>User-Agent: Pixray-Seeker
Disallow: /</code></pre>
<p>Here a specific User-agent is defined, so the rules that follow only refer to
the crawler “Pixray-Seeker”. Here there is only one Disallow rule, namely “/”.
“/” is short for “everything”. So the Pixray-Seeker crawler is not to allowed to
access any content on the website.</p>
</div>
</div>
<div id="reduce-traffic" class="section level2" number="9.2">
<h2><span class="header-section-number">9.2</span> Reduce traffic</h2>
<p>Every time a website is accessed, traffic is generated. Traffic here refers to
the transfer of the HTML data from the website’s server to our computer. This
produces monetary costs on the side of the providers of the website. Many
websites are financed through advertisements. When we download the website
directly from R using <code>read_html()</code>, we are circumventing the ad display in
browser and thus the provider will get no revenue. Both may seem negligible in
many cases, but if we aim to act respectful to the website providers, we should
reduce unnecessary traffic when we are able to.</p>
<p><strong>Collect only once (if possible)</strong></p>
<p>The most simple step we can undertake is to not download the HTML code every
time we re-run our script. This reduces traffic and also makes our code faster
to execute. See chapter <a href="files.html#files">8</a> on how to save the downloaded HTML files.</p>
<p><strong>Test, test, test</strong></p>
<p>We should also test our code on a small scale before finally running it on large
amounts of data. If our aim is to download a large number of websites and/or
files, we should make sure that our code actually works. While there are
problems in our code – and there will be – we may create a lot of unnecessary
traffic during bugfixing. If we instead test our code until we are sure it will
run without errors on a single instead of multiple pages, we will reduce traffic
and again also reduce the time we have to wait for the downloads to finish.</p>
<p><strong>Set waiting times</strong></p>
<p>If we are downloading many pages or files, it may also be a good idea to slow
down the process on our end by setting a waiting time between each
download. This will spread our traffic over time. If a server detects
unusually large amounts of site requests, it may even block our IP which would
make us unable to continue our downloads. Waiting between each request can
potentially prevent this. A waiting time between 2-5 seconds should be enough in
most cases. Sometimes the robots.txt also gives a guideline on a desired waiting
time for a specific site.</p>
<div id="waiting-times-in-action" class="section level3" number="9.2.1">
<h3><span class="header-section-number">9.2.1</span> Waiting times in action</h3>
<p>Let us have another look on the first example from chapter <a href="rvest3.html#rvest3">7</a> to see
how to set waiting times in practice when downloading multiple pages with
`read_html()``.</p>
<p>First, let us generate the list of links we want to download like we did in
chapter <a href="rvest3.html#rvest3">7</a>.</p>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="good-practice.html#cb174-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb174-2"><a href="good-practice.html#cb174-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rvest)</span>
<span id="cb174-3"><a href="good-practice.html#cb174-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-4"><a href="good-practice.html#cb174-4" aria-hidden="true" tabindex="-1"></a>website <span class="ot">&lt;-</span> <span class="st">&quot;https://www.tidyverse.org/packages/&quot;</span> <span class="sc">%&gt;%</span> </span>
<span id="cb174-5"><a href="good-practice.html#cb174-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">read_html</span>()</span>
<span id="cb174-6"><a href="good-practice.html#cb174-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-7"><a href="good-practice.html#cb174-7" aria-hidden="true" tabindex="-1"></a>a_nodes <span class="ot">&lt;-</span> website <span class="sc">%&gt;%</span> </span>
<span id="cb174-8"><a href="good-practice.html#cb174-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">html_nodes</span>(<span class="at">css =</span> <span class="st">&quot;div.package &gt; a&quot;</span>)</span>
<span id="cb174-9"><a href="good-practice.html#cb174-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-10"><a href="good-practice.html#cb174-10" aria-hidden="true" tabindex="-1"></a>links <span class="ot">&lt;-</span> a_nodes <span class="sc">%&gt;%</span></span>
<span id="cb174-11"><a href="good-practice.html#cb174-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">html_attr</span>(<span class="at">name =</span> <span class="st">&quot;href&quot;</span>)</span></code></pre></div>
<p>To let R wait for several seconds, we can use the base R function <code>Sys.sleep()</code>
which takes the seconds to wait as its only argument. As we want the <code>map()</code>
function to add the waiting time before each <code>read_html()</code> iteration, we have to
include <code>Sys.sleep()</code> into the iteration process. We can achieve this by
defining a multi-line formula using the <code>~ {...}</code> notation. The arguments passed
to this formula can be accessed via any name starting with <code>.</code>, so we will just
use <code>.x</code> in this case. Each new line enclosed by the <code>{}</code> is run once for each
iteration over the object we pass to <code>map</code>. For each element of the <code>links</code>
object, R first waits for two seconds and then uses <code>read_html()</code> on the element
of <code>links</code>. So in effect we added a waiting time of two seconds between each
iteration. Note that <code>read_html()</code> has to come last if we want this short
notation to work because only the return value of the last function within the
curly braces is assigned to <code>pages</code>.</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="good-practice.html#cb175-1" aria-hidden="true" tabindex="-1"></a>pages <span class="ot">&lt;-</span> links <span class="sc">%&gt;%</span> </span>
<span id="cb175-2"><a href="good-practice.html#cb175-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map</span>(<span class="sc">~</span> {</span>
<span id="cb175-3"><a href="good-practice.html#cb175-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">Sys.sleep</span>(<span class="dv">2</span>)</span>
<span id="cb175-4"><a href="good-practice.html#cb175-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">read_html</span>(.x)</span>
<span id="cb175-5"><a href="good-practice.html#cb175-5" aria-hidden="true" tabindex="-1"></a>  })</span></code></pre></div>
</div>
</div>
<div id="citation-and-additional-resource" class="section level2" number="9.3">
<h2><span class="header-section-number">9.3</span> Citation and additional resource</h2>
<p>Some of the ideas expressed above are in part based on the subchapter “9.3 Web
scraping: Good practice” from: Munzert et. al (2015). Automated Data Collection
with R. A Practical Guide to Web Scraping and Text Mining. Chichester: Wiley.
The authors also describe some guidelines of a good practice of web scraping
that in part overlap with the set of guidelines presented here but go beyond
this in describing the technical implementation in R and also the legal
situation by way of some examples. A read is highly recommended.</p>

</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="files.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="dplyr.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/webscraping-tures/webscraping-tures.github.io/09-good_practice.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
